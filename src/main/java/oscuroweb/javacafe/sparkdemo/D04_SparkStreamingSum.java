package oscuroweb.javacafe.sparkdemo;

import org.apache.log4j.Level;
import org.apache.log4j.Logger;
import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.api.java.StorageLevels;
import org.apache.spark.streaming.Durations;
import org.apache.spark.streaming.api.java.JavaPairDStream;
import org.apache.spark.streaming.api.java.JavaReceiverInputDStream;
import org.apache.spark.streaming.api.java.JavaStreamingContext;
import org.apache.spark.util.LongAccumulator;

import scala.Tuple2;

public class D04_SparkStreamingSum {

	/** Batch interval in seconds. */
	private static int INVERVAL = 5;

	public static String ONE = "1";

	public static void main(String[] args) {

		Logger.getLogger("org").setLevel(Level.ERROR);

		if (args.length < 2) {
			System.err.println("Usage: StreamingSumNumbers  <hostname> <port>");
			System.exit(1);
		}

		// Create a local StreamingContext with two 
		// working thread and batch interval of 1 second
		SparkConf conf = new SparkConf()
				.setMaster("local[2]")
				.setAppName("Streaming Sum Count");

		JavaStreamingContext context = new JavaStreamingContext(conf, Durations.seconds(INVERVAL));

		// Create a JavaReceiverInputDStream on target ip:port and count the
		// words in input stream of \n delimited text (eg. generated by 'nc -l port')
		JavaReceiverInputDStream<String> lines = context.socketTextStream(args[0], Integer.parseInt(args[1]),
				StorageLevels.MEMORY_AND_DISK_SER);


		JavaPairDStream<String, Integer> numbers = lines
				.map(line -> {
						try {
							return Integer.valueOf(line);
						} catch (NumberFormatException e) {
							System.out.println("Incorrect Number Format");
							return 0;
						}
					})
				.mapToPair(number -> new Tuple2<String, Integer>(ONE, number))
				.reduceByKey((value1, value2) -> value1 + value2);
	
		numbers.foreachRDD((number, time) -> {
			final LongAccumulator droppedSumNumber = JavaDroppedSumNumber
					.getInstance(new JavaSparkContext(number.context()));

			// droppedWordsCounter to count them
			number.filter(tuple -> {
				droppedSumNumber.add(tuple._2());
				return true;
			})
			.collect();

			System.out.println("Accumulated sum " + droppedSumNumber.value());
		});

		numbers.print();
		context.start();
		
		try {
			context.awaitTermination();
		} catch (InterruptedException e) {
			System.out.println("Bye!");
		}

		// Stop the spark context
		context.stop();
	}

	static class JavaDroppedSumNumber {

		private static volatile LongAccumulator instance = null;

		public static LongAccumulator getInstance(JavaSparkContext jsc) {
			if (instance == null) {
				synchronized (JavaDroppedSumNumber.class) {
					if (instance == null) {
						instance = jsc.sc().longAccumulator("AcumulatedSum");
					}
				}
			}
			return instance;
		}
	}
}
